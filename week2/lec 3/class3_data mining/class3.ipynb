{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI100B Python Project (Fall, 2022): \n",
    "# Social Exploration Based on Data Processing - Class 3: Data Mining (21 points)\n",
    "***\n",
    "\n",
    "Update: `2022-12-5 21:00` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this week, we will do some amazing work called data mining. In general, data collection and data preprocessing are done before data mining as you should finish it in class 1 and 2. We mainly introduce two topics here and offer toy exercises for you to practice. We hope it will inspire you to dive deeper into your data. We also encourage you to do more work besides clustering and regression, such as dimension reduction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining\n",
    "What is data mining? \n",
    "\n",
    "`\"Data mining is the discovery of models for data\" -- Rajaraman, Ullman.`\n",
    "\n",
    "We can have the following types of models:\n",
    "- Models that explain the data (e.g., a single function)\n",
    "- Models that predict future data instances\n",
    "- Models that summarize the data\n",
    "- Models the extract the most prominent features of the data\n",
    " \n",
    " “Data Mining is the study of collecting, processing, analyzing, and gaining useful insights from data\" -– Charu Aggarwal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "What is a Clustering?\n",
    "\n",
    "- A grouping of objects such that the objects in a group (cluster) are similar (or related) to one another and different from (or unrelated to) the objects in other groups (clusters).\n",
    "\n",
    "Why do we need cluster analysis?\n",
    "- Understanding: Group related documents for browsing, genes and proteins that have similar functionality, stocks with similar price fluctuations, users with similar behavior\n",
    "- Summarization: Reduce the size of large data sets\n",
    "- Applications: Recommendation systems, Search Personalization\n",
    "\n",
    "Here we introduce 2 clustering objectives:\n",
    "1. center-based clusters:\n",
    "- A cluster is a set of objects such that an object in a cluster is closer (more similar) to the “center” of a cluster, than to the center of any other cluster\n",
    "- The center of a cluster is often a centroid, the minimizer of distances from all the points in the cluster\n",
    "2. density-based clusters:\n",
    "- A cluster is a dense region of points, which is separated by low-density regions, from other regions of high density\n",
    "- Used when the clusters are irregular or intertwined, and when noise and outliers are present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means\n",
    "\n",
    "K-means may be the most famous and easiest clustering method. It is a center-based clustering algorithm.\n",
    "\n",
    "### Parameters\n",
    "\n",
    "- K: the number of clusters, must be specified.\n",
    "\n",
    "### Objective:\n",
    "\n",
    "- find K centroids\n",
    "- the assignment of points to clusters/centroids\n",
    "- minimize the sum of distances of the points to their respective centroid\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "```\n",
    "Select K points as the initial centroids\n",
    "while the centroids do change (a lot)\n",
    " \tForm K clusters by assigning each point to the closest centroid\n",
    " \tCompute the new centroid of each cluster(take mean of all points in a cluster to compute its centroid)\n",
    "```\n",
    "\n",
    "### Remind\n",
    "\n",
    "Besides the number of clusters `K`, the distance function is also defined by ourselves. Pay attention to these two things, they may have great effect on your clustering result.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "DBSCAN is a density-based clustering algorithm. We provide a brief description of this algorithm for reference. Since it is a little complicated, you do not need to understand it thoroughly and you can directly use a third-party library's implementation such as `sklearn`. \n",
    "*** \n",
    "### Parameters\n",
    "- Eps: The maximum distance between two points for one to be considered as in the neighborhood of the other.\n",
    "- MinPts: The number of points in a neighborhood for a point to be considered as a core point. This includes the point itself.\n",
    "\n",
    "### Characterization of points\n",
    "- A point is a `core point` if it has more than or equal to a specified number of points (`MinPts`) within `Eps`. These points belong in a dense region and are at the interior of a cluster.\n",
    "- A `border point` has fewer than `MinPts` within `Eps`, but is in the neighborhood of a `core` point.\n",
    "- A `noise point` is any point that is not a core point or a border point.\n",
    "### Density-Connected points\n",
    "-  Density edge: We place an edge between two core points q and p if they are within distance `Eps`.\n",
    "- Density-connected: A point p is `density-connected` to a point q if there is a path of edges from p to q.\n",
    "### Algorithm\n",
    "- Label points as core, border and noise\n",
    "- Eliminate noise points\n",
    "- For every core point p that has not been assigned to a cluster. Create a new cluster with the point p and all the points that are density-connected to p.\n",
    "- Assign border points to the cluster of the closest core point.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "Regression is a predictive modeling technique in which the estimated target variable is continuous.\n",
    "\n",
    "Let‘s start with an example. We want to have a system that can predict the price of a used car. Inputs are the car attributes—brand, year, engine capacity, mileage, and other information that we believe affects a car's worth. The output is the price of the car. Such problems where the output is a number are regression problems. Let X denote the car attributes and Y be the price of the car. Again surveying the past transactions, we can collect training data and the machine learning program fits a function to this data to learn Y as a function of X.\n",
    "\n",
    "We assume that we have k feature variables (numeric), which also known as covariates, or independent variables. The target variable is also known as dependent variable.\n",
    "\n",
    "We are given a dataset of the form $\\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\\}$  where $x_i$ is a k-dimensional feature vector, and $y_i$ a real value.\n",
    "\n",
    "We want to learn a function $f$ which given a feature vector $x_i$ predicts \n",
    "a value $y_i' = f(x_i)$ that is as close as possible to the value $y_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "The simplest form of $f$ is a linear function.\n",
    "\n",
    "In linear regression the function $f$ is typically of the form: $f(x_i)=w_0+\\sum_{j=1}^{k}w_jx_{ij}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises (19 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clustering (10 points)\n",
    "### Background\n",
    "We provide 2 toy datasets, `toy1.npy` and `toy2.npy`, which can be opened by `numpy`. You can directly plot them without clustering to do observation. Intuitively, they are just clustered into 2 groups by their shape.\n",
    "\n",
    "### Action\n",
    "1. Implement K-means by **yourself** (without third-party library except `numpy`) and plot the result.\n",
    "2. Implement DBSCAN and plot the result.\n",
    "\n",
    "### Remind\n",
    "- Use Euclidean distance as the distance function.\n",
    "- You should do clustering for both datasets. In other words, there should be 2*2 = 4 plots.\n",
    "\n",
    "### Questions (The answers are not unique)\n",
    "- Compare their differences (if exist) and explain.\n",
    "- Give one situation that both clustering methods will achieve good results. You should describe it by text, generate it by code and plot the clustering result.\n",
    "\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def Kmeans(data: np.ndarray, k: int, centers: np.ndarray = None):\n",
    "    #Your code here\n",
    "    return\n",
    "\n",
    "def dist(X: np.ndarray,Y: np.ndarray):\n",
    "    #Your code here\n",
    "    return\n",
    "\n",
    "def nearest(X: np.ndarray,C: np.ndarray):\n",
    "    #Your code here\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('toy1.npy')\n",
    "#Plot the result of toy1.npy below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('toy2.npy')\n",
    "#Plot the result of toy2.npy below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prediction Based On Betting Markets (9 points)\n",
    "\n",
    "### Background\n",
    "\n",
    "Here, we study the prediction of election outcomes based on betting markets. In\n",
    "particular, we analyze data for the 2008 and 2012 US presidential elections from the\n",
    "online betting company called Intrade. At Intrade, people trade contracts such as\n",
    "“Obama to win the electoral votes of Florida.” Each contract’s market price fluctuates\n",
    "based on its sales. Why might we expect betting markets like Intrade to accurately\n",
    "predict the outcomes of elections or of other events? Some argue that the market can\n",
    "aggregate available information efficiently. In this exercise, we will test this efficient\n",
    "market hypothesis by analyzing the market prices of contracts for Democratic and\n",
    "Republican nominees’ victories in each state.\n",
    "\n",
    "The data files for 2008 and 2012 are available in CSV format as intrade08.csv\n",
    "and `intrade12.csv`, respectively. Table 4.9 presents the names and descriptions\n",
    "of these data sets. Each row of the data sets represents daily trading information\n",
    "about the contracts for either the Democratic or Republican Party nominee’s victory\n",
    "in a particular state. We will also use the election outcome data. These data files are\n",
    "`pres08.csv` (table 4.1) and `pres12.csv` (table 4.5).\n",
    "\n",
    "| Variable     | Description                                                  |\n",
    "| ------------ | ------------------------------------------------------------ |\n",
    "| `day`        | date of the session                                          |\n",
    "| `statename`  | full name of each state (including District of Columbia in 2008) |\n",
    "| `state`      | abbreviation of each state (including District of Columbia in 2008) |\n",
    "| `PriceD`     | closing price (predicted vote share) of the Democratic nominee’s market |\n",
    "| `PriceR`     | closing price (predicted vote share) of the Republican nominee’s market |\n",
    "| `VolumeD`    | total session trades of the Democratic Party nominee’s market |\n",
    "| `VolumeR`    | total session trades of the Republican Party nominee’s market |\n",
    "\n",
    "### Action\n",
    "1. We will begin by using the market prices on the day before the election to predict\n",
    "the 2008 election outcome.\n",
    "\n",
    "\t(1) Subset the data such that it contains the\n",
    "market information for each state and candidate on the day before the election\n",
    "only. Note that in 2008, Election Day was November 4. \n",
    "\n",
    "\t(2) We compare the closing\n",
    "prices for the two candidates in a given state and classify a candidate whose\n",
    "contract has a higher price as the predicted winner of that state.\n",
    "\n",
    "\t(3) Repeat the same analysis for the 2012 election, which was\n",
    "held on November 6.\n",
    "\n",
    "\tNote that in 2012 some less competitive states have missing data on\n",
    "the day before the election because there were no trades on the Republican\n",
    "and Democratic betting markets. Assume Intrade predictions would have been\n",
    "accurate for these states.\n",
    "\n",
    "2. How do the predictions based on the betting markets change over time? \n",
    "   \n",
    "\t(1) Implement the same classification procedure as above on each of the last 90 days of\n",
    "the 2008 campaign rather than just the day before the election. \n",
    "\n",
    "\t(2) Plot the predicted number of electoral votes for the Democratic Party nominee over this 90-day\n",
    "period. The resulting plot should also indicate the actual election result. Briefly comment on the plot.\n",
    "\tNote that in 2008, Obama won 365 electoral votes. \n",
    "\n",
    "3.  Repeat the previous exercise but this time use the seven-day moving-average\n",
    "price, instead of the daily price, for each candidate within a state.\n",
    "For a given day, we take the average of the Session Close prices within the past seven days (including that day). To\n",
    "answer this question, we must \n",
    "\n",
    "\t(1) Compute the seven-day average within each state. \n",
    "\n",
    "\t(2) We sum the electoral votes for the states Obama is predicted to win.\n",
    "Using the tapply() function will allow us to efficiently compute the predicted\n",
    "winner for each state on a given day.\n",
    "\n",
    "In the code below,\n",
    "- Implement the function `predict_by_previous_day`.\n",
    "- Implement the function `predict_by_ninety_days`.\n",
    "- Implement the function `cal_moving_avg`, add two additional columns named 'PriceD_MA' and 'PriceR_MA' for two elections, and the new dataframe should only contain 90 days before the election. Write the new csvs to 'intrade08_MA.csv' and 'intrade12_MA.csv'.\n",
    "- Implement the function `predict_by_moving_avg` to get the prediction results.\n",
    "\n",
    "### Questions (The answers are not unique)\n",
    "- Which states were misclassified?\n",
    "- How well did the prediction market do in 2012 compared to 2008? \n",
    "- How do the predictions based on the betting markets change over time? Briefly comment on the plot.\n",
    "\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predict_by_previous_day(csv_file_path, day_before_election):\n",
    "    #Your code here\n",
    "    return\n",
    "\n",
    "winner = predict_by_previous_day('intrade08.csv', day_before_election='2008-11-03')\n",
    "print('Predicted winner of 2008:', winner)\n",
    "winner = predict_by_previous_day('intrade12.csv', day_before_election='2008-11-05')\n",
    "print('Predicted winner of 2012:', winner)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_ninety_days(csv_file_path, election_date):\n",
    "    #Your code here\n",
    "    return\n",
    "\n",
    "def plot_ninety_days():\n",
    "    pass\n",
    "\n",
    "winner = predict_by_ninety_days('intrade08.csv', election_date='2008-11-04')\n",
    "print('Predicted winner of 2008:', winner)\n",
    "winner = predict_by_ninety_days('intrade12.csv', election_date='2012-11-06')\n",
    "print('Predicted winner of 2012:', winner)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def cal_moving_avg(csv_file_path, election_date, filename):\n",
    "    #Your code here\n",
    "    return\n",
    "\n",
    "def predict_by_moving_avg(csv_file_path, election_date):\n",
    "    #Your code here\n",
    "    return\n",
    "\n",
    "df = cal_moving_avg('intrade08.csv', election_date='2008-11-04', filename='intrade08_MA.csv')\n",
    "df = cal_moving_avg('intrade12.csv', election_date='2012-11-06', filename='intrade12_MA.csv')\n",
    "\n",
    "winner = predict_by_moving_avg('intrade08.csv', election_date='2008-11-04')\n",
    "print('Predicted winner of 2008:', winner)\n",
    "\n",
    "winner = predict_by_moving_avg('intrade12.csv', election_date='2012-11-06')\n",
    "print('Predicted winner of 2012:', winner)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task (2 points)\n",
    "\n",
    "Now, you need to show us some of your milestones.\n",
    "\n",
    "- What data do you currently use? What is the access to them?\n",
    "- What questions have you asked about your topic? Have these questions been answered so far? How have you answered them?\n",
    "- What variables can this week's content help you to investigate? Have you made any assumptions when applying this week's content?\n",
    "\n",
    "Don't worry about not answering these questions perfectly. In fact, the point is, whether you have thought about these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "CS173, Data Mining\n",
    "\n",
    "<!-- CS181, Artificial Intelligence -->\n",
    "\n",
    "Quantative Social Science An Introduction, Kosuke Imai\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
